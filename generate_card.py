import requests
import pyperclip
import json
import re
from duckduckgo_search import DDGS
from gtts import gTTS
import base64
from io import BytesIO
import requests
from bs4 import BeautifulSoup
import termios
import tty
import os
import sys
import webbrowser
import tempfile
import html

# == –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è ==
MODEL_NAME = "VocabCard_English_UA"
DECK_NAME = "Default"
PEXELS_API_KEY = 'R6T2MCrfCrNxu5SrXkO2OSapt8kJTwl4GYTFmEnSHQturYOKztFJAqXU'
BIG_HUGE_API_KEY = '7d4ebb0df20e98dde8f3604e6759ab01'  # Big Huge Thesaurus API key

def get_char():
    """Get a single character from standard input"""
    fd = sys.stdin.fileno()
    old_settings = termios.tcgetattr(fd)
    try:
        tty.setraw(sys.stdin.fileno())
        ch = sys.stdin.read(1)
    finally:
        termios.tcsetattr(fd, termios.TCSADRAIN, old_settings)
    return ch

def create_image_gallery(images, word):
    """Create a temporary HTML file with image gallery"""
    html_content = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>–í–∏–±—ñ—Ä –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–ª—è '{word}'</title>
        <style>
            body {{
                font-family: Arial, sans-serif;
                max-width: 1200px;
                margin: 0 auto;
                padding: 20px;
                background: #f5f5f5;
            }}
            .gallery {{
                display: grid;
                grid-template-columns: repeat(3, 1fr);
                gap: 20px;
                margin-top: 20px;
            }}
            .image-container {{
                background: white;
                padding: 15px;
                border-radius: 8px;
                box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            }}
            .image-container img {{
                width: 100%;
                height: 250px;
                object-fit: cover;
                border-radius: 4px;
            }}
            .image-info {{
                margin-top: 10px;
                font-size: 14px;
                color: #666;
            }}
            h1 {{
                color: #333;
                text-align: center;
            }}
            .instructions {{
                text-align: center;
                margin: 20px 0;
                padding: 15px;
                background: #e9ecef;
                border-radius: 8px;
            }}
        </style>
    </head>
    <body>
        <h1>–í–∏–±—ñ—Ä –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–ª—è '{word}'</h1>
        <div class="instructions">
            <p>üëÄ –ü–µ—Ä–µ–≥–ª—è–Ω—å—Ç–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –Ω–∏–∂—á–µ —Ç–∞ –∑–∞–ø–∞–º'—è—Ç–∞–π—Ç–µ –Ω–æ–º–µ—Ä (1-6) –±–∞–∂–∞–Ω–æ–≥–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è.</p>
            <p>–ü–æ–≤–µ—Ä–Ω—ñ—Ç—å—Å—è –¥–æ —Ç–µ—Ä–º—ñ–Ω–∞–ª—É –¥–ª—è –≤–∏–±–æ—Ä—É.</p>
        </div>
        <div class="gallery">
    """
    
    for i, image in enumerate(images, 1):
        html_content += f"""
            <div class="image-container">
                <img src="{html.escape(image['url'])}" alt="–í–∞—Ä—ñ–∞–Ω—Ç {i}">
                <div class="image-info">
                    <strong>–ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è {i}</strong><br>
                    –ê–≤—Ç–æ—Ä: {html.escape(image['photographer'])}<br>
                    <a href="{html.escape(image['pexels_url'])}" target="_blank">–ü–µ—Ä–µ–≥–ª—è–Ω—É—Ç–∏ –Ω–∞ Pexels</a>
                </div>
            </div>
        """
    
    html_content += """
        </div>
    </body>
    </html>
    """
    
    # Create temporary file
    with tempfile.NamedTemporaryFile(delete=False, suffix='.html', mode='w', encoding='utf-8') as f:
        f.write(html_content)
        return f.name

def fetch_images(word, num_images=6):
    """Fetch multiple images from Pexels"""
    url = f"https://api.pexels.com/v1/search?query={word}&per_page={num_images}"
    headers = {
        "Authorization": PEXELS_API_KEY
    }
    try:
        print(f"\nüîç Sending request to Pexels API...")
        response = requests.get(url, headers=headers)  # Added headers parameter
        print(f"üì° Status code: {response.status_code}")
        
        if response.status_code != 200:
            print(f"‚ùå API Error: {response.text}")
            return []
            
        data = response.json()
        if data.get("photos"):
            images = [
                {
                    "url": photo["src"]["medium"],
                    "photographer": photo["photographer"],
                    "pexels_url": photo["url"]
                }
                for photo in data["photos"]
            ]
            print(f"‚úÖ Found {len(images)} images")
            return images
            
        print("‚ùå No photos found in API response")
        print(f"üìù API Response: {data}")
        return []
    except Exception as e:
        print(f"‚ùå Error fetching images: {str(e)}")
        return []

def select_image(images, word):
    """Interactive image selection interface with visual preview"""
    if not images:
        print("–ó–æ–±—Ä–∞–∂–µ–Ω—å –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return None
    
    # Create and open gallery
    gallery_path = create_image_gallery(images, word)
    webbrowser.open('file://' + os.path.abspath(gallery_path))
    
    while True:
        try:
            choice = input("\nüî¢ –í–≤–µ–¥—ñ—Ç—å –Ω–æ–º–µ—Ä –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è (1-6) –∞–±–æ –Ω–∞—Ç–∏—Å–Ω—ñ—Ç—å Enter –¥–ª—è –ø—Ä–æ–ø—É—Å–∫—É: ").strip()
            
            if not choice:  # Skip image selection
                os.unlink(gallery_path)
                return None
                
            choice = int(choice)
            if 1 <= choice <= len(images):
                os.unlink(gallery_path)
                return images[choice - 1]['url']
            else:
                print(f"‚ùå –ë—É–¥—å –ª–∞—Å–∫–∞, –≤–≤–µ–¥—ñ—Ç—å —á–∏—Å–ª–æ –≤—ñ–¥ 1 –¥–æ {len(images)}")
        except ValueError:
            print("‚ùå –ë—É–¥—å –ª–∞—Å–∫–∞, –≤–≤–µ–¥—ñ—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–µ —á–∏—Å–ª–æ")

def detect_pos_from_context(word, sentence):
    """Simple rule-based POS detection"""
    word = word.lower()
    sentence = sentence.lower()
    
    # Find the word and its surrounding context
    word_pattern = re.compile(r'\b' + re.escape(word) + r'\w*\b')
    match = word_pattern.search(sentence)
    if not match:
        return None
        
    words = sentence.split()
    word_index = None
    for i, w in enumerate(words):
        if word in w:
            word_index = i
            break
            
    if word_index is None:
        return None
        
    # Simple rules for POS detection
    # Check for adjective
    if word.endswith(('able', 'ible', 'al', 'ful', 'ic', 'ive', 'less', 'ous')):
        return "adjective"
    
    # Check for adverb
    if word.endswith('ly'):
        return "adverb"
    
    # Check for verb
    if word_index > 0:
        prev_word = words[word_index - 1]
        if prev_word in ['to', 'will', 'would', 'could', 'should', 'may', 'might', 'must', 'can']:
            return "verb"
    
    # Check for common verb endings
    if word.endswith(('ate', 'ize', 'ise', 'ify')):
        return "verb"
    
    # Default to noun if no other patterns match
    return "noun"

def fetch_thesaurus_data(word, pos=None):
    """
    Fetch all lexical relationships from Big Huge Thesaurus for specific part of speech.
    Returns a dictionary containing synonyms, antonyms, related words, and similar words.
    """
    url = f"https://words.bighugelabs.com/api/2/{BIG_HUGE_API_KEY}/{word}/json"
    
    # Map our POS to Big Huge Thesaurus format
    pos_mapping = {
        "noun": "noun",
        "verb": "verb",
        "adjective": "adjective",
        "adverb": "adverb"
    }
    
    try:
        print(f"\nüîç –ó–∞–ø–∏—Ç –¥–æ Big Huge Thesaurus –¥–ª—è —Å–ª–æ–≤–∞ '{word}'...")
        response = requests.get(url)
        
        if response.status_code != 200:
            print(f"‚ö†Ô∏è Thesaurus: –ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ –¥–∞–Ω—ñ –¥–ª—è '{word}'")
            print(f"üì° –ö–æ–¥ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ: {response.status_code}")
            return {
                "synonyms": [],
                "antonyms": [],
                "related": [],
                "similar": []
            }
            
        data = response.json()
        print("‚úÖ –û—Ç—Ä–∏–º–∞–Ω–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –≤—ñ–¥ Big Huge Thesaurus")
        
        # Debug: print available parts of speech in response
        print(f"üìö –î–æ—Å—Ç—É–ø–Ω—ñ —á–∞—Å—Ç–∏–Ω–∏ –º–æ–≤–∏: {', '.join(data.keys())}")
        
        # Initialize result containers
        all_synonyms = []
        all_antonyms = []
        all_related = []
        all_similar = []
        
        # If POS is specified, only look in that section
        if pos and pos in pos_mapping:
            mapped_pos = pos_mapping[pos]
            pos_data = data.get(mapped_pos, {})
            
            if pos_data:
                all_synonyms.extend(pos_data.get('syn', []))
                all_antonyms.extend(pos_data.get('ant', []))
                all_related.extend(pos_data.get('rel', []))
                all_similar.extend(pos_data.get('sim', []))
        else:
            # If no POS specified or not found, gather from all parts of speech
            for pos_section in data.values():
                if isinstance(pos_section, dict):
                    all_synonyms.extend(pos_section.get('syn', []))
                    all_antonyms.extend(pos_section.get('ant', []))
                    all_related.extend(pos_section.get('rel', []))
                    all_similar.extend(pos_section.get('sim', []))
        
        # Remove duplicates while preserving order
        def deduplicate(lst):
            seen = set()
            return [x for x in lst if not (x in seen or seen.add(x))]
        
        result = {
            "synonyms": deduplicate(all_synonyms),
            "antonyms": deduplicate(all_antonyms),
            "related": deduplicate(all_related),
            "similar": deduplicate(all_similar)
        }
        
        # Debug output
        print("\nüìù –ó–Ω–∞–π–¥–µ–Ω—ñ –∑–≤'—è–∑–∫–∏:")
        for key, values in result.items():
            if values:
                print(f"   {key.capitalize()}: {len(values)} —Å–ª—ñ–≤")
                print(f"   –ü—Ä–∏–∫–ª–∞–¥: {', '.join(values[:5])}...")
        
        return result
        
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ Thesaurus API: {str(e)}")
        return {
            "synonyms": [],
            "antonyms": [],
            "related": [],
            "similar": []
        }

def fetch_dictionary_data(word, requested_pos=None):
    """
    Fetch word data from dictionary API with optional POS filtering.
    When POS is specified, returns only definitions, synonyms, and antonyms
    from that specific part of speech.
    """
    url = f"https://api.dictionaryapi.dev/api/v2/entries/en/{word}"
    try:
        response = requests.get(url)
        if response.status_code != 200:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: —Å–ª–æ–≤–æ '{word}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ —É —Å–ª–æ–≤–Ω–∏–∫—É.")
            return None
            
        data = response.json()[0]
        meanings = data.get("meanings", [])
        
        # If POS is specified, strictly filter by that part of speech
        if requested_pos:
            matching_meanings = [m for m in meanings if m.get("partOfSpeech") == requested_pos]
            if matching_meanings:
                meaning = matching_meanings[0]
            else:
                print(f"‚ö†Ô∏è –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è –¥–ª—è —á–∞—Å—Ç–∏–Ω–∏ –º–æ–≤–∏ '{requested_pos}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
                return None
        else:
            meaning = meanings[0] if meanings else None
            
        if not meaning:
            return None
            
        definitions = meaning.get("definitions", [])
        if not definitions:
            return None
            
        # Get thesaurus data
        thes_data = fetch_thesaurus_data(word, requested_pos)
        
        # Format results
        def format_word_list(words):
            return ", ".join(words) if words else "No words found"
            
        return {
            "definition": definitions[0].get("definition", ""),
            "example": definitions[0].get("example", ""),
            "synonyms": format_word_list(thes_data["synonyms"]),
            "antonyms": format_word_list(thes_data["antonyms"]),
            "related": format_word_list(thes_data["related"]),
            "similar": format_word_list(thes_data["similar"]),
            "partOfSpeech": meaning.get("partOfSpeech", "")
        }
        
    except Exception as e:
        print(f"‚ùå –í–∏–Ω—è—Ç–æ–∫ –ø—Ä–∏ –æ—Ç—Ä–∏–º–∞–Ω–Ω—ñ –¥–∞–Ω–∏—Ö –∑—ñ —Å–ª–æ–≤–Ω–∏–∫–∞: {e}")
        return None

# == –ó—á–∏—Ç—É—î–º–æ —Ä–µ—á–µ–Ω–Ω—è –∑ –±—É—Ñ–µ—Ä–∞ ==
# sentence = re.sub(r'\s+', ' ', pyperclip.paste().replace('\n', ' ')).strip()
# print(f"\nüìã –°–∫–æ–ø—ñ–π–æ–≤–∞–Ω–µ —Ä–µ—á–µ–Ω–Ω—è:\n{sentence}\n")

# == –ó—á–∏—Ç—É—î–º–æ —Ä–µ—á–µ–Ω–Ω—è –∑ –±—É—Ñ–µ—Ä–∞ —ñ –æ—á–∏—â—É—î–º–æ ==
raw_text = pyperclip.paste()

# –û–±—Ä–æ–±–∫–∞:
# 1. –í–∏–¥–∞–ª—è—î–º–æ –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω–Ω—è –∑ –¥–µ—Ñ—ñ—Å–æ–º (generos-\nity ‚Üí generosity)
# 2. –ü—Ä–∏–±–∏—Ä–∞—î–º–æ –≤—Å—ñ –ø–µ—Ä–µ–Ω–æ—Å–∏ —Ä—è–¥–∫—ñ–≤ (–∑–∞–ª–∏—à–∫–∏)
# 3. –ü—Ä–∏–±–∏—Ä–∞—î–º–æ –∑–∞–π–≤—ñ –ø—Ä–æ–±—ñ–ª–∏ –ø–µ—Ä–µ–¥ —Ä–æ–∑–¥—ñ–ª–æ–≤–∏–º–∏ –∑–Ω–∞–∫–∞–º–∏
# 4. –ó–∞–º—ñ–Ω–∞ –¥–µ–∫—ñ–ª—å–∫–æ—Ö –ø—Ä–æ–±—ñ–ª—ñ–≤ –Ω–∞ –æ–¥–∏–Ω
import re
sentence = raw_text
sentence = re.sub(r'-\s*\n\s*', '', sentence)       # –ø–µ—Ä–µ–Ω–æ—Å —ñ–∑ –¥–µ—Ñ—ñ—Å–æ–º
sentence = re.sub(r'\s*\n\s*', ' ', sentence)        # –∑–≤–∏—á–∞–π–Ω—ñ –ø–µ—Ä–µ–Ω–æ—Å–∏
sentence = re.sub(r'\s+([.,:;!?])', r'\1', sentence) # –ø—Ä–æ–±—ñ–ª –ø–µ—Ä–µ–¥ –ø—É–Ω–∫—Ç—É–∞—Ü—ñ—î—é
sentence = re.sub(r'\s{2,}', ' ', sentence)          # –ø–æ–¥–≤—ñ–π–Ω—ñ –ø—Ä–æ–±—ñ–ª–∏
sentence = sentence.strip()

print(f"\nüìã –°–∫–æ–ø—ñ–π–æ–≤–∞–Ω–µ —Ä–µ—á–µ–Ω–Ω—è:\n{sentence}\n")


# == –ó–∞–ø–∏—Ç —Å–ª–æ–≤–∞ ==
word = input("üî§ –í–≤–µ–¥–∏ —Å–ª–æ–≤–æ, —è–∫–µ —Ö–æ—á–µ—à –≤–∏–≤—á–∞—Ç–∏: ").strip().lower()

# Detect part of speech and show it in the prompt
detected_pos = detect_pos_from_context(word, sentence) or "noun"
pos = input(f"üìù –ß–∞—Å—Ç–∏–Ω–∞ –º–æ–≤–∏ [{detected_pos}] [–ù–∞—Ç–∏—Å–Ω–∏ Enter –¥–ª—è –ø—ñ–¥—Ç–≤–µ—Ä–¥–∂–µ–Ω–Ω—è –∞–±–æ –ø–æ–º—ñ–Ω—è–π (noun/verb/adjective/adverb)]: ").strip().lower()
if not pos:
    pos = detected_pos

# Get dictionary data with POS
data = fetch_dictionary_data(word, pos)
if not data:
    exit(1)

# == –ü—ñ–¥—Å–≤—ñ—á–µ–Ω–Ω—è —Å–ª–æ–≤–∞ –≤ —Ä–µ—á–µ–Ω–Ω—ñ ==
highlighted = re.sub(
    rf'\b({re.escape(word)}\w*)\b',
    r'<span style="color:orange;font-weight:bold">\1</span>',
    sentence,
    count=1,
    flags=re.IGNORECASE
)

# == Image Selection ==
print("\nüîç –ü–æ—à—É–∫ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å...")
images = fetch_images(word)
if images:
    print(f"–ó–Ω–∞–π–¥–µ–Ω–æ {len(images)} –∑–æ–±—Ä–∞–∂–µ–Ω—å. –í—ñ–¥–∫—Ä–∏–≤–∞—é –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ–π –ø–µ—Ä–µ–≥–ª—è–¥ —É –±—Ä–∞—É–∑–µ—Ä—ñ...")
    image_url = select_image(images, word)
    if image_url:
        print("‚úÖ –ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è —É—Å–ø—ñ—à–Ω–æ –≤–∏–±—Ä–∞–Ω–æ.")
    else:
        print("‚ö†Ô∏è –ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è –Ω–µ –≤–∏–±—Ä–∞–Ω–æ. –ü—Ä–æ–¥–æ–≤–∂—É—é –±–µ–∑ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è.")
else:
    print("‚ö†Ô∏è –ó–æ–±—Ä–∞–∂–µ–Ω—å –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –ü—Ä–æ–¥–æ–≤–∂—É—é –±–µ–∑ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è.")
    image_url = ""

# == –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –æ–∑–≤—É—á–∫–∏ (mp3 –≤ base64) ==
def generate_tts_base64(text):
    try:
        tts = gTTS(text)
        buffer = BytesIO()
        tts.write_to_fp(buffer)
        buffer.seek(0)
        encoded = base64.b64encode(buffer.read()).decode('utf-8')
        return f"[sound:tts_{word}.mp3]", encoded
    except requests.exceptions.ConnectionError:
        print("\n‚ùå –ü–æ–º–∏–ª–∫–∞: –ù–µ –≤–¥–∞–ª–æ—Å—è –ø—ñ–¥–∫–ª—é—á–∏—Ç–∏—Å—è –¥–æ —Å–µ—Ä–≤—ñ—Å—É TTS. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ —ñ–Ω—Ç–µ—Ä–Ω–µ—Ç—É.")
        return None, None
    except Exception as e:
        print(f"\n‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó TTS: {str(e)}")
        return None, None

word_audio_ref, word_audio_data = generate_tts_base64(word)
if word_audio_ref is None or word_audio_data is None:
    print("‚ÑπÔ∏è –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–∞—Ä—Ç–∫–∏ —á–µ—Ä–µ–∑ –ø–æ–º–∏–ª–∫—É TTS. –°–ø—Ä–æ–±—É–π—Ç–µ –Ω–∞—Å—Ç—É–ø–Ω–µ —Ä–µ—á–µ–Ω–Ω—è.")
    exit(0)

sentence_audio_ref, sentence_audio_data = generate_tts_base64(sentence)
if sentence_audio_ref is None or sentence_audio_data is None:
    print("‚ÑπÔ∏è –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–∞—Ä—Ç–∫–∏ —á–µ—Ä–µ–∑ –ø–æ–º–∏–ª–∫—É TTS. –°–ø—Ä–æ–±—É–π—Ç–µ –Ω–∞—Å—Ç—É–ø–Ω–µ —Ä–µ—á–µ–Ω–Ω—è.")
    exit(0)

# == –î–æ–¥–∞–≤–∞–Ω–Ω—è –º—É–ª—å—Ç–∏–º–µ–¥—ñ–π–Ω–∏—Ö —Ñ–∞–π–ª—ñ–≤ –¥–æ Anki ==
def check_anki_connect():
    """Check if AnkiConnect is available"""
    try:
        response = requests.get("http://localhost:8765")
        return True
    except requests.exceptions.ConnectionError:
        print("\n‚ùå –ü–æ–º–∏–ª–∫–∞: –ù–µ –≤–¥–∞–ª–æ—Å—è –ø—ñ–¥–∫–ª—é—á–∏—Ç–∏—Å—è –¥–æ Anki.")
        print("üìù –ü–µ—Ä–µ–∫–æ–Ω–∞–π—Ç–µ—Å—è, —â–æ:")
        print("   1. Anki –∑–∞–ø—É—â–µ–Ω–æ")
        print("   2. –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –¥–æ–¥–∞—Ç–æ–∫ AnkiConnect")
        print("   3. AnkiConnect –Ω–∞–ª–∞—à—Ç–æ–≤–∞–Ω–æ –Ω–∞ –ø–æ—Ä—Ç 8765")
        return False

def send_media_file(name, b64_data):
    """Send media file to Anki with error handling"""
    try:
        result = requests.post("http://localhost:8765", json={
            "action": "storeMediaFile",
            "version": 6,
            "params": {
                "filename": name,
                "data": b64_data
            }
        }, timeout=5).json()
        
        if result.get("error"):
            print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –¥–æ–¥–∞–≤–∞–Ω–Ω—è {name}: {result['error']}")
            return False
        else:
            print(f"üìÅ –§–∞–π–ª {name} –∑–±–µ—Ä–µ–∂–µ–Ω–æ")
            return True
            
    except requests.exceptions.ConnectionError:
        print(f"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–±–µ—Ä–µ–≥—Ç–∏ {name}: –Ω–µ–º–∞—î –∑ º—î–¥–Ω–∞–Ω–Ω—è –∑ Anki")
        return False
    except Exception as e:
        print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—ñ {name}: {str(e)}")
        return False

# Before sending files to Anki, check connection
anki_available = check_anki_connect()

if word_audio_data:
    if anki_available:
        send_media_file(f"tts_{word}.mp3", word_audio_data)
    else:
        print("‚ö†Ô∏è –ê—É–¥—ñ–æ —Ñ–∞–π–ª –Ω–µ –±—É–¥–µ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —á–µ—Ä–µ–∑ –≤—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å –∑ º—î–¥–Ω–∞–Ω–Ω—è –∑ Anki")

if sentence_audio_data:
    if anki_available:
        send_media_file(f"tts_sentence_{word}.mp3", sentence_audio_data)
    else:
        print("‚ö†Ô∏è –ê—É–¥—ñ–æ —Ñ–∞–π–ª —Ä–µ—á–µ–Ω–Ω—è –Ω–µ –±—É–¥–µ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —á–µ—Ä–µ–∑ –≤—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å –∑ º—î–¥–Ω–∞–Ω–Ω—è –∑ Anki")

# == –§–æ—Ä–º—É–≤–∞–Ω–Ω—è –∫–∞—Ä—Ç–∫–∏ ==
if anki_available:
    note = {
        "deckName": DECK_NAME,
        "modelName": MODEL_NAME,
        "fields": {
            "Word": word,
            "Front": "",
            "Back": "",
            "Image": f'<img src="{image_url}">' if image_url else "",
            "Definition": data["definition"],
            "Synonyms": data["synonyms"],
            "Antonyms": data["antonyms"],
            "Related": data["related"],
            "Similar": data["similar"],
            "Sentence": highlighted,
            "Sentence_Repeated": sentence,
            "Sentence_Audio": "[sound:tts_sentence_{0}.mp3]".format(word) if sentence_audio_data else "",
            "Word_Audio": word_audio_ref,
            "Dictionary_Entry": "",
            "Translation_UA": "",
            "Tags": ""
        },
        "options": {
            "allowDuplicate": False
        },
        "tags": []
    }

    try:
        result = requests.post("http://localhost:8765", json={
            "action": "addNote",
            "version": 6,
            "params": {"note": note}
        }, timeout=5).json()

        if result.get("error") is None:
            print(f"‚úÖ –ö–∞—Ä—Ç–∫—É –¥–æ–¥–∞–Ω–æ: ID = {result['result']}")
        else:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –¥–æ–¥–∞–≤–∞–Ω–Ω—è –∫–∞—Ä—Ç–∫–∏: {result['error']}")
            
    except requests.exceptions.ConnectionError:
        print("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –¥–æ–¥–∞—Ç–∏ –∫–∞—Ä—Ç–∫—É: –Ω–µ–º–∞—î –∑ º—î–¥–Ω–∞–Ω–Ω—è –∑ Anki")
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –¥–æ–¥–∞–≤–∞–Ω–Ω—ñ –∫–∞—Ä—Ç–∫–∏: {str(e)}")
else:
    print("\n‚ö†Ô∏è –ö–∞—Ä—Ç–∫—É –Ω–µ –±—É–ª–æ –¥–æ–¥–∞–Ω–æ —á–µ—Ä–µ–∑ –≤—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å –∑ º—î–¥–Ω–∞–Ω–Ω—è –∑ Anki")
    print("üí° –©–æ–± –¥–æ–¥–∞—Ç–∏ –∫–∞—Ä—Ç–∫—É –ø—ñ–∑–Ω—ñ—à–µ:")
    print(f"   1. –ó–∞–ø—É—Å—Ç—ñ—Ç—å Anki")
    print(f"   2. –ü–µ—Ä–µ–∫–æ–Ω–∞–π—Ç–µ—Å—è, —â–æ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ AnkiConnect")
    print(f"   3. –ó–∞–ø—É—Å—Ç—ñ—Ç—å —Å–∫—Ä–∏–ø—Ç –∑–Ω–æ–≤—É")
