import requests
import pyperclip
import json
import re
from duckduckgo_search import DDGS
from gtts import gTTS
import base64
from io import BytesIO
import requests
from bs4 import BeautifulSoup

# == –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è ==
MODEL_NAME = "VocabCard_English_UA"
DECK_NAME = "Default"

def detect_pos_from_context(word, sentence):
    """Simple rule-based POS detection"""
    word = word.lower()
    sentence = sentence.lower()
    
    # Find the word and its surrounding context
    word_pattern = re.compile(r'\b' + re.escape(word) + r'\w*\b')
    match = word_pattern.search(sentence)
    if not match:
        return None
        
    words = sentence.split()
    word_index = None
    for i, w in enumerate(words):
        if word in w:
            word_index = i
            break
            
    if word_index is None:
        return None
        
    # Simple rules for POS detection
    # Check for adjective
    if word.endswith(('able', 'ible', 'al', 'ful', 'ic', 'ive', 'less', 'ous')):
        return "adjective"
    
    # Check for adverb
    if word.endswith('ly'):
        return "adverb"
    
    # Check for verb
    if word_index > 0:
        prev_word = words[word_index - 1]
        if prev_word in ['to', 'will', 'would', 'could', 'should', 'may', 'might', 'must', 'can']:
            return "verb"
    
    # Check for common verb endings
    if word.endswith(('ate', 'ize', 'ise', 'ify')):
        return "verb"
    
    # Default to noun if no other patterns match
    return "noun"

def fetch_dictionary_data(word, requested_pos=None):
    """Fetch word data from dictionary API with optional POS filtering"""
    url = f"https://api.dictionaryapi.dev/api/v2/entries/en/{word}"
    try:
        response = requests.get(url)
        if response.status_code != 200:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: —Å–ª–æ–≤–æ '{word}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ —É —Å–ª–æ–≤–Ω–∏–∫—É.")
            return None
            
        data = response.json()[0]
        meanings = data.get("meanings", [])
        
        # If POS is specified, try to find matching definition
        if requested_pos:
            matching_meanings = [m for m in meanings if m.get("partOfSpeech") == requested_pos]
            if matching_meanings:
                meaning = matching_meanings[0]
            else:
                meaning = meanings[0] if meanings else None
                if meaning:
                    print(f"‚ö†Ô∏è –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –¥–ª—è —á–∞—Å—Ç–∏–Ω–∏ –º–æ–≤–∏: {meaning.get('partOfSpeech')}")
        else:
            meaning = meanings[0] if meanings else None
            
        if not meaning:
            return None
            
        definitions = meaning.get("definitions", [])
        if not definitions:
            return None
            
        return {
            "definition": definitions[0].get("definition", ""),
            "example": definitions[0].get("example", ""),
            "synonyms": ", ".join(definitions[0].get("synonyms", [])[:5]),
            "partOfSpeech": meaning.get("partOfSpeech", "")
        }
        
    except Exception as e:
        print(f"‚ùå –í–∏–Ω—è—Ç–æ–∫: {e}")
        return None

# == –ó—á–∏—Ç—É—î–º–æ —Ä–µ—á–µ–Ω–Ω—è –∑ –±—É—Ñ–µ—Ä–∞ ==
sentence = re.sub(r'\s+', ' ', pyperclip.paste().replace('\n', ' ')).strip()
print(f"\nüìã –°–∫–æ–ø—ñ–π–æ–≤–∞–Ω–µ —Ä–µ—á–µ–Ω–Ω—è:\n{sentence}\n")

# == –ó–∞–ø–∏—Ç —Å–ª–æ–≤–∞ ==
word = input("üî§ –í–≤–µ–¥–∏ —Å–ª–æ–≤–æ, —è–∫–µ —Ö–æ—á–µ—à –≤–∏–≤—á–∞—Ç–∏: ").strip().lower()

# Detect part of speech and show it in the prompt
detected_pos = detect_pos_from_context(word, sentence) or "noun"
pos = input(f"üìù –ß–∞—Å—Ç–∏–Ω–∞ –º–æ–≤–∏ [{detected_pos}] [–ù–∞—Ç–∏—Å–Ω–∏ Enter –¥–ª—è –ø—ñ–¥—Ç–≤–µ—Ä–¥–∂–µ–Ω–Ω—è –∞–±–æ –ø–æ–º—ñ–Ω—è–π (noun/verb/adjective/adverb)]: ").strip().lower()
if not pos:
    pos = detected_pos

# Get dictionary data with POS
data = fetch_dictionary_data(word, pos)
if not data:
    exit(1)

# == –ü—ñ–¥—Å–≤—ñ—á–µ–Ω–Ω—è —Å–ª–æ–≤–∞ –≤ —Ä–µ—á–µ–Ω–Ω—ñ ==
highlighted = re.sub(
    rf'\b({re.escape(word)}\w*)\b',
    r'<span style="color:orange;font-weight:bold">\1</span>',
    sentence,
    count=1,
    flags=re.IGNORECASE
)

# == –ü–æ—à—É–∫ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —á–µ—Ä–µ–∑ DuckDuckGo ==
# def get_image_url(query):
#    try:
#        with DDGS() as ddgs:
#            results = ddgs.images(query)
#            for r in results:
#                return r["image"]
#    except Exception as e:
#        print(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è: {e}")
#        return ""

'''
def get_image_url(word):
    """
    –ü–æ–≤–µ—Ä—Ç–∞—î –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ –ø–µ—Ä—à–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑—ñ —Å–ª–æ–≤–æ–º.
    –î–∂–µ—Ä–µ–ª–æ: Google Images —á–µ—Ä–µ–∑ DuckDuckGo (–±–µ–∑ API)
    """
    search_url = f"https://duckduckgo.com/?q={word}+english+definition&iax=images&ia=images"
    headers = {'User-Agent': 'Mozilla/5.0'}

    try:
        response = requests.get(search_url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')
        img_tags = soup.find_all('img')

        # –ü–æ—à—É–∫ –ø–µ—Ä—à–æ–≥–æ –≤–∞–ª—ñ–¥–Ω–æ–≥–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
        for img in img_tags:
            src = img.get('src')
            if src and src.startswith("http"):
                return src

        return None  # –Ø–∫—â–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ

    except Exception as e:
        print(f"[Error] Failed to fetch image for '{word}':", e)
        return None
'''        

PEXELS_API_KEY = 'R6T2MCrfCrNxu5SrXkO2OSapt8kJTwl4GYTFmEnSHQturYOKztFJAqXU'

def get_image_url(word):
    url = f"https://api.pexels.com/v1/search?query={word}&per_page=1"
    headers = {
        "Authorization": PEXELS_API_KEY
    }
    response = requests.get(url, headers=headers)
    data = response.json()
    if data["photos"]:
        return data["photos"][0]["src"]["medium"]
    else:
        return ""                

image_url = get_image_url(word)

# == –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –æ–∑–≤—É—á–∫–∏ (mp3 –≤ base64) ==
def generate_tts_base64(text):
    try:
        tts = gTTS(text)
        buffer = BytesIO()
        tts.write_to_fp(buffer)
        buffer.seek(0)
        encoded = base64.b64encode(buffer.read()).decode('utf-8')
        return f"[sound:tts_{word}.mp3]", encoded
    except requests.exceptions.ConnectionError:
        print("\n‚ùå –ü–æ–º–∏–ª–∫–∞: –ù–µ –≤–¥–∞–ª–æ—Å—è –ø—ñ–¥–∫–ª—é—á–∏—Ç–∏—Å—è –¥–æ —Å–µ—Ä–≤—ñ—Å—É TTS. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ —ñ–Ω—Ç–µ—Ä–Ω–µ—Ç—É.")
        return None, None
    except Exception as e:
        print(f"\n‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó TTS: {str(e)}")
        return None, None

word_audio_ref, word_audio_data = generate_tts_base64(word)
if word_audio_ref is None or word_audio_data is None:
    print("‚ÑπÔ∏è –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–∞—Ä—Ç–∫–∏ —á–µ—Ä–µ–∑ –ø–æ–º–∏–ª–∫—É TTS. –°–ø—Ä–æ–±—É–π—Ç–µ –Ω–∞—Å—Ç—É–ø–Ω–µ —Ä–µ—á–µ–Ω–Ω—è.")
    exit(0)

sentence_audio_ref, sentence_audio_data = generate_tts_base64(sentence)
if sentence_audio_ref is None or sentence_audio_data is None:
    print("‚ÑπÔ∏è –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–∞—Ä—Ç–∫–∏ —á–µ—Ä–µ–∑ –ø–æ–º–∏–ª–∫—É TTS. –°–ø—Ä–æ–±—É–π—Ç–µ –Ω–∞—Å—Ç—É–ø–Ω–µ —Ä–µ—á–µ–Ω–Ω—è.")
    exit(0)

# == –î–æ–¥–∞–≤–∞–Ω–Ω—è –º—É–ª—å—Ç–∏–º–µ–¥—ñ–π–Ω–∏—Ö —Ñ–∞–π–ª—ñ–≤ –¥–æ Anki ==
def send_media_file(name, b64_data):
    result = requests.post("http://localhost:8765", json={
        "action": "storeMediaFile",
        "version": 6,
        "params": {
            "filename": name,
            "data": b64_data
        }
    }).json()
    if result.get("error"):
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –¥–æ–¥–∞–≤–∞–Ω–Ω—è {name}: {result['error']}")
    else:
        print(f"üìÅ –§–∞–π–ª {name} –∑–±–µ—Ä–µ–∂–µ–Ω–æ")

if word_audio_data:
    send_media_file(f"tts_{word}.mp3", word_audio_data)
if sentence_audio_data:
    send_media_file(f"tts_sentence_{word}.mp3", sentence_audio_data)

# == –§–æ—Ä–º—É–≤–∞–Ω–Ω—è –∫–∞—Ä—Ç–∫–∏ ==
note = {
    "deckName": DECK_NAME,
    "modelName": MODEL_NAME,
    "fields": {
        "Word": word,
        "Front": "",
        "Back": "",
        "Image": f'<img src="{image_url}">' if image_url else "",
        "Definition": data["definition"],
        "Sentence": highlighted,
        "Sentence_Repeated": sentence,
        "Sentence_Audio": "[sound:tts_sentence_{0}.mp3]".format(word) if sentence_audio_data else "",
        "Word_Audio": word_audio_ref,
        "Dictionary_Entry": "",
        "Translation_UA": "",
        "Tags": ""
    },
    "options": {
        "allowDuplicate": False
    },
    "tags": []
}

# == –ù–∞–¥—Å–∏–ª–∞–Ω–Ω—è –¥–æ AnkiConnect ==
result = requests.post("http://localhost:8765", json={
    "action": "addNote",
    "version": 6,
    "params": {"note": note}
}).json()

if result.get("error") is None:
    print(f"‚úÖ –ö–∞—Ä—Ç–∫—É –¥–æ–¥–∞–Ω–æ: ID = {result['result']}")
else:
    print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {result['error']}")
